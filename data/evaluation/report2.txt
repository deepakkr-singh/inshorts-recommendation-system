Content-Based Fallback Mechanism - Deep Dive

  The fallback mechanism is a safety net that ensures every user gets recommendations even when the primary algorithm fails. Think of it as a decision tree with multiple backup plans.

  ---
  Scenario 1: User Has No TF-IDF Profile (288 users = 3.2%)

  Why This Happens:

  # Building user TF-IDF profiles
  user_profiles = build_user_profiles_optimized(merged)
  # merged = events.csv + training_content.csv

  # Some users only read articles that DON'T have category metadata
  # Total users in events: 8,977
  # Users with category data: 8,689
  # Users WITHOUT category data: 288 (3.2%)

  Real Example:
  User ID: abc123
  Reading history:
    - Article A (hashid: xyz789) â†’ NOT in training_content.csv (ghost article)
    - Article B (hashid: def456) â†’ NOT in training_content.csv (ghost article)
    - Article C (hashid: ghi111) â†’ NOT in training_content.csv (ghost article)

  Result: User has 3 interactions but 0 category data
  â†’ user_category_tfidf[abc123] = DOES NOT EXIST

  What Happens in Code:

  # In ContentBasedRecommender.recommend()

  if user_id not in self.user_category_tfidf.index:
      # User has no TF-IDF profile
      # CANNOT compute cosine_similarity(user_tfidf, article_tfidf)
      # 
      # Fallback: Return top 50 popular articles
      popular_articles = sorted(
          self.article_popularity.items(),
          key=lambda x: x[1],
          reverse=True
      )[:50]

      return popular_articles

  Why 100% Popularity?
  - No user interests â†’ Cannot match categories
  - No language data â†’ Cannot match language
  - No location data â†’ Cannot match geography
  - Only option: Recommend what everyone else likes (popularity)

  Affected Users:
  - 288 out of 8,977 users (3.2%)
  - These are users whose reading history consists ONLY of ghost articles (articles in events.csv but not in training_content.csv)

  ---
  Scenario 2: Article Not in TF-IDF Vocabulary

  Why This Happens:

  # TF-IDF vocabulary is built from training articles
  tfidf_vectorizer.fit(training_content['categories'])
  # Vocabulary: 38 categories (after min_df=2 filtering)

  # Testing articles use the SAME vocabulary
  testing_tfidf = tfidf_vectorizer.transform(testing_content['categories'])

  # If a testing article has ONLY rare categories not in vocabulary:
  # Example: "rare_event_xyz, super_niche_topic"
  # â†’ TF-IDF vector = [0, 0, 0, ..., 0] (all zeros)

  Real Example:
  Article: hashid = test789
  Categories: "olympics_2024, special_coverage_xyz"

  TF-IDF Vocabulary (38 categories):
    ['sports', 'cricket', 'technology', 'business', ...]
    
  'olympics_2024' â†’ NOT in vocabulary (too rare, appeared in <2 articles)
  'special_coverage_xyz' â†’ NOT in vocabulary

  Result: article_tfidf[test789] = [0, 0, 0, ..., 0] (38 zeros)

  What Happens in Code:

  # Compute content similarity
  content_sim = user_tfidf @ article_tfidf.T

  # For this article:
  # user_tfidf = [0.5, 0.3, 0.1, ..., 0.2]  (38 values)
  # article_tfidf = [0, 0, 0, ..., 0]        (38 zeros)
  # 
  # content_sim = 0.5*0 + 0.3*0 + ... + 0.2*0 = 0.0

  if content_sim == 0.0:
      # Cannot use content similarity
      # Fallback: Use popularity + language match

      score = 0.60 * popularity_score + 0.40 * language_match_score

      # language_match_score:
      if user.preferred_language == article.newsLanguage:
          language_match = 1.0
      else:
          language_match = 0.0

  Why 60% Popularity + 40% Language?
  - 60% Popularity: Most reliable signal when content fails
  - 40% Language: At least match user's language preference (Hindi user â†’ Hindi articles)

  How Rare Is This?
  - Very rare in practice
  - Most articles have at least 1-2 common categories (sports, entertainment, etc.)
  - More likely for special event coverage with unique tags

  ---
  Scenario 3: Low Content Similarity (all scores < 0.1)

  Why This Happens:

  # User reads ONLY sports articles
  user_category_tfidf = [0.8, 0.2, 0.0, 0.0, ..., 0.0]
  #                       â†‘    â†‘
  #                    sports cricket (all other categories = 0)

  # Candidate articles are about technology, business, politics
  article1_tfidf = [0.0, 0.0, 0.7, 0.3, 0.0, ...]  # technology, business
  article2_tfidf = [0.0, 0.0, 0.0, 0.0, 0.9, ...]  # politics
  article3_tfidf = [0.0, 0.0, 0.5, 0.5, 0.0, ...]  # tech, business

  # Similarity scores:
  similarity(user, article1) = 0.8*0.0 + 0.2*0.0 + ... = 0.0
  similarity(user, article2) = 0.0
  similarity(user, article3) = 0.0

  # ALL similarities are very low (< 0.1)

  Real Example:
  User: die-hard sports fan
    - Reads 100% sports/cricket articles
    - TF-IDF profile: [sports: 0.9, cricket: 0.7, football: 0.5, rest: 0.0]

  Article Pool (validation set):
    - 20% are sports articles (already recommended, high scores)
    - 80% are non-sports (technology, politics, business, entertainment)

  When recommending from the 80% non-sports pool:
    - All content similarities < 0.1 (user interests don't match)
    - Risk: Recommending irrelevant articles with low confidence

  What Happens in Code:

  # Compute all similarities
  similarities = user_tfidf @ articles_tfidf.T  # (1, n_articles)

  # Check if ALL scores are very low
  max_similarity = similarities.max()

  if max_similarity < 0.1:
      # User's interests are TOO different from available articles
      # Content-based confidence is LOW
      #
      # Fallback: Boost popularity weight

      # Normal formula:
      # score = content_sim + 0.15*popularity + 0.10*language
      #       = ~0.05 + 0.15*0.8 + 0.10*1.0 = 0.27 (low!)

      # Fallback formula:
      score = 0.30 * content_sim + 0.70 * popularity
      #     = 0.30*0.05 + 0.70*0.8 = 0.575 (better!)

  Why 30% Content + 70% Popularity?
  - 30% Content: Still use weak signals (maybe 0.05 is better than 0.02)
  - 70% Popularity: Let crowd wisdom guide (if user won't like content, at least give them what's popular)

  When This Triggers:
  - Echo chamber users: Only read one topic
  - Article pool mismatch: Available articles don't match user's niche interests
  - Diversity injection: Forces some variety even for niche users

  Example Ranking:

  User: sports-only reader (content_sim â‰ˆ 0.05 for non-sports)

  Articles:
  1. Tech article: popularity = 0.9, content_sim = 0.02
  2. Business article: popularity = 0.7, content_sim = 0.05
  3. Politics article: popularity = 0.5, content_sim = 0.03

  Normal weights (75% content + 15% pop):
    Tech:     0.75*0.02 + 0.15*0.9 = 0.150
    Business: 0.75*0.05 + 0.15*0.7 = 0.143
    Politics: 0.75*0.03 + 0.15*0.5 = 0.098
    â†’ Business wins (but all scores are low)

  Fallback weights (30% content + 70% pop):
    Tech:     0.30*0.02 + 0.70*0.9 = 0.636  â† WINNER
    Business: 0.30*0.05 + 0.70*0.7 = 0.505
    Politics: 0.30*0.03 + 0.70*0.5 = 0.359
    â†’ Popular tech article wins (better user experience)

  ---
  Fallback Decision Tree (Visual)

  Start: Recommend for User X
  â”‚
  â”œâ”€ Check: Does user have TF-IDF profile?
  â”‚  â”œâ”€ NO â†’ [FALLBACK 1] Return top 50 popular articles (100% popularity)
  â”‚  â””â”€ YES â†’ Continue
  â”‚
  â”œâ”€ Compute: content_similarity for all articles
  â”‚
  â”œâ”€ Check: Any articles have TF-IDF > 0?
  â”‚  â”œâ”€ NO (all zeros) â†’ [FALLBACK 2] Use 60% popularity + 40% language
  â”‚  â””â”€ YES â†’ Continue
  â”‚
  â”œâ”€ Check: Max content_similarity >= 0.1?
  â”‚  â”œâ”€ NO (all < 0.1) â†’ [FALLBACK 3] Use 30% content + 70% popularity
  â”‚  â””â”€ YES â†’ Continue
  â”‚
  â””â”€ Use Normal Formula: ~75% content + 15% popularity + 10% language

  ---
  Key Insights

  Why Multiple Fallbacks?
  - Graceful degradation: Never fail completely, always return something
  - User experience: Better to give popular articles than crash or give garbage
  - Coverage: 96.8% of users get full Content-Based, 3.2% get fallbacks

  Weight Philosophy:
  - More data â†’ lower popularity weight: If we have strong signals, trust them
  - Less data â†’ higher popularity weight: If uncertain, follow the crowd

  Real-World Impact:

  | Scenario   | Users Affected     | Recommendation Quality           |
  |------------|--------------------|----------------------------------|
  | Fallback 1 | 288 (3.2%)         | Moderate (popular articles)      |
  | Fallback 2 | <10 (<0.1%)        | Moderate (language + popularity) |
  | Fallback 3 | ~500-1,000 (5-10%) | Good (diverse, popular)          |
  | Normal     | ~8,200 (91%)       | Best (personalized)              |

  This cascading fallback system ensures every user gets recommendations, with quality degrading gracefully based on available data!


  âš ï¸ DISCREPANCIES:

  1. Article Location Coverage

  - Report says: "Training: 17.8% city-specific, Testing: 0% NATIONAL"
  - Actual: 13,702 total articles with locations (11.9% city-specific, 88.1% NATIONAL)
  - Issue: Report claims 9,140 articles, actual has 13,702 (includes both training + testing)

  2. User Profile Columns

  - Report says: num_reads, num_clicks, num_bookmarks, num_shares, top_categories
  - Actual columns: ['deviceId', 'category_text', 'num_interactions', 'language_preference', 'user_city', 'preferred_newsType', 'segment']
  - Issue: Missing the detailed interaction breakdowns, has segment instead of top_categories

  3. Algorithm Weights

  - Report says (Section 4):
    - Content-Based: 0.15 Ã— popularity + 0.10 Ã— language
  - Actual implementation:
    - Content-Based: category_sim * 0.50 + lang * 0.15 + pop * 0.15 + type * 0.10 + geo * 0.10
  - Issue: Report oversimplifies - doesn't mention type preference (10%) and geo (10%) clearly

  4. Hybrid Weights

  - Report says: Fixed 60% collab + 25% content + 15% pop
  - Actual: DYNAMIC weights based on user segment:
    - Passive (1.0): 100% content
    - Active (0.5): 50-50 blend
    - VeryActive (0.3): 30% content, 70% collab
    - Power (0.2): 20% content, 80% collab
  - Issue: Report presents a simplified version, actual is more sophisticated with segment-based Î± weights

  ---
  ðŸ”´ MAJOR GAP:

  Geographic Scoring Values

  - Report says: 1.0 local, 0.7 NATIONAL, 0.5 different city
  - Actual implementation: 1.0 local, 0.3 non-local, 0.5 unknown
  - Issue: Report shows 0.7 for NATIONAL, code shows 0.3 for non-local (lines 1571, 1954-1956)